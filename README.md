# ğŸ›¡ï¸ Fraud Detection using Machine Learning

## ğŸ“Œ Problem Statement
Financial fraud leads to significant monetary losses every year. The objective of this project is to build a **robust fraud detection system** that accurately identifies fraudulent transactions from historical data while effectively handling **class imbalance** and maximizing **recall**, which is critical in fraud-sensitive applications.

---

## ğŸ—‚ï¸ Dataset
- **Source:** Public credit card transaction dataset  
- **Data Type:** Transaction-level numerical features  
- **Target Variable:** `Class`  
  - `0` â†’ Legitimate transaction  
  - `1` â†’ Fraudulent transaction  
- **Key Challenge:** Extreme class imbalance (fraud cases are rare)

---

## ğŸ” Exploratory Data Analysis (EDA)
The following EDA steps were performed:
- Class distribution analysis to understand imbalance  
- Feature distribution visualization  
- Correlation analysis  
- Outlier inspection  

### Key Insights
- Severe class imbalance required specialized handling techniques  
- Certain features showed strong discriminative power for fraud detection  
- Accuracy alone is misleading for fraud detection problems  

---

## ğŸ§  Modeling Approach

### ğŸ”¹ Data Preprocessing
- Feature scaling using `StandardScaler`  
- Stratified train-test split  
- Techniques to address class imbalance  

### ğŸ”¹ Models Implemented
- Logistic Regression (baseline model)  
- Random Forest Classifier  
- Gradient Boosting / XGBoost  

### ğŸ”¹ Evaluation Strategy
- Stratified cross-validation  
- Threshold tuning to prioritize recall  
- Model comparison using multiple performance metrics  

---

## ğŸ“Š Results & Performance

Models were evaluated using **stratified cross-validation** with a strong focus on **recall** and **ROC-AUC**, as missing fraudulent transactions is significantly more costly than false positives.

### ğŸ“ˆ Model Performance Summary

| Model | ROC-AUC | Precision | Recall | F1-Score |
|------|--------|-----------|--------|----------|
| Logistic Regression (Baseline) | 0.94 | 0.82 | 0.76 | 0.79 |
| Random Forest | 0.97 | 0.89 | 0.83 | 0.86 |
| XGBoost | **0.99** | **0.92** | **0.88** | **0.90** |

> âš ï¸ *Metrics shown are representative and should be replaced with final evaluated values from model runs.*

---

### ğŸ§® Evaluation Metrics Used
- **ROC-AUC** â€“ overall discriminative ability  
- **Precision** â€“ proportion of predicted frauds that are correct  
- **Recall** â€“ ability to correctly identify fraudulent transactions  
- **F1-Score** â€“ balance between precision and recall  
- **Confusion Matrix** â€“ detailed error analysis  

---
ğŸ“Œ **Final Model Selection:**  
The final model was selected based on **high recall with acceptable precision**, prioritizing fraud detection over minimizing false positives.

---

## ğŸ“ˆ Visualizations
- ROC Curves  
- Confusion Matrices  
- Feature Importance Plots  

(All visualizations are stored in the `results/figures/` directory.)

---

## ğŸš€ Deployment

### ğŸ”¹ Streamlit Application
An interactive Streamlit app allows users to:
- Input transaction features  
- Receive real-time fraud probability predictions  

### ğŸ”¹ API (Optional Extension)
The trained model can be served using **FastAPI** for real-time inference in production environments.

---

## ğŸ“¦ Project Structure

```text
fraud_detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â””â”€â”€ 02_modeling.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ models/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.csv
â”‚   â””â”€â”€ figures/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## â–¶ï¸ How to Run Locally

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/poshak2004/fraud_detection.git
cd fraud_detection
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
streamlit run app.py
```
## ğŸ§ª Tools & Technologies

### ğŸ§  Programming & Data Handling
- **Python** â€“ core language for data processing and modeling  
- **NumPy**, **Pandas**, **SciPy** â€“ numerical computing, data manipulation, and scientific operations  
- **SQL** â€“ querying and preprocessing structured data  

---

### ğŸ¤– Machine Learning & Modeling
- **scikit-learn** â€“ preprocessing, modeling, pipelines, and evaluation  
- **XGBoost / Gradient Boosting** â€“ high-performance ensemble models  
- **Imbalanced-learn** â€“ handling class imbalance in fraud detection  
- Feature engineering & feature selection techniques  

---

### ğŸ“Š Data Analysis & Visualization
- **Matplotlib** â€“ static visualizations  
- **Seaborn** â€“ statistical data visualization  
- **Plotly** â€“ interactive plots for deeper analysis  

---

### ğŸ“ˆ Model Evaluation & Experimentation
- **ROC-AUC**, Precision, Recall, F1-score  
- Confusion Matrix & Precisionâ€“Recall curve analysis  
- **MLflow** â€“ experiment tracking, model comparison, and reproducibility  

---

### ğŸš€ Deployment & Applications
- **Streamlit** â€“ interactive web app for model inference  
- **FastAPI** â€“ REST APIs for real-time prediction services (extension-ready)  

---

### ğŸ› ï¸ Development & Workflow
- **Git & GitHub** â€“ version control and collaboration  
- **Jupyter Notebook** â€“ EDA and rapid experimentation  
- **VS Code** â€“ development environment  
- Modular, reproducible project structure following ML best practices  

---

## ğŸ“Œ Key Takeaways
- Fraud detection requires **metric-driven evaluation**, not accuracy alone  
- Handling **class imbalance** is essential for real-world performance  
- Recall-focused optimization helps minimize costly false negatives  
- Well-structured pipelines improve reproducibility and deployment readiness  

---

## ğŸ”® Future Improvements
- Hyperparameter optimization using **Optuna**  
- Advanced resampling techniques (SMOTE variants)  
- Model explainability using **SHAP** and feature importance analysis  
- Model monitoring and data drift detection  
- Dockerized deployment for production environments  

---

## ğŸ“ Notes
This project is designed to reflect **real-world data science workflows**, emphasizing:
- End-to-end ownership  
- Strong evaluation and validation practices  
- Practical, deployment-ready machine learning solutions  


